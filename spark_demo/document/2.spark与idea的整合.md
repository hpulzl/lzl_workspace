#spark与idea的整合
# 前言
首先要保证已经安装好spark的环境

# idea中基于maven的工程创建(java实现)

1. 创建一个`maven-archetype-quickstart`的maven项目
2. pom.xml文件

	pom文件中引入`sprark-core`的依赖

   ```
 	<dependency>
      <groupId>org.apache.spark</groupId>
      <artifactId>spark-core_2.11</artifactId>
      <version>2.2.0</version>
    </dependency>
	```
3. 写一个wordCount的实例

> wordCount就是统计一个文件或者一个集合里面相同单词出现的次数的一个例子。我们使用spark的API可以很快速方便的完成统计，而不用去担心其内部的算法实现!

	```
	 	public class SparkFirst {
	    private static SparkConf conf;
	    private static JavaSparkContext sc;
	    public static void main(String[] args) {
	//        firstSparkJava();
	        wordCount();
	    }
	
	    static {
	        /**
	         * 第一步:创建spark的配置对象SparkConf，设置spark程序运行时的配置信息，
	         * setMaster设置程序要链接的spark集群的master的URL
	         */
	        conf = new SparkConf().setAppName("my first spark demo").setMaster("local");
	        sc = new JavaSparkContext(conf);
	    }
	    /**
	     * 统计一个串字符串中，字母出现的次数
	     */
	    public static void wordCount(){
	        String[] strings = new String[]{"words","word","name","hello","name","word","come","on","hello"};
	        JavaRDD<String> lines = sc.parallelize(Arrays.asList(strings));
	//        JavaPairRDD<String,Integer> pairRDD = lines.mapToPair(s -> new Tuple2<String, Integer>(s,1));
	        JavaPairRDD<String,Integer> pairRDD = lines.mapToPair(new PairFunction<String, String, Integer>() {
	            @Override
	            public Tuple2<String, Integer> call(String s) throws Exception {
	                return new Tuple2<>(s,1);
	            }
	        });
	//        JavaPairRDD<String,Integer> counts = pairRDD.reduceByKey((a,b) -> a + b);
	        JavaPairRDD<String,Integer> counts = pairRDD.reduceByKey(new Function2<Integer, Integer, Integer>() {
	            @Override
	            public Integer call(Integer integer, Integer integer2) throws Exception {
	                return integer + integer2;
	            }
	        });
	
	//        counts.foreach(stringIntegerTuple2 ->System.out.println("str:" + stringIntegerTuple2._1() +
	//                "=> count:" + stringIntegerTuple2._2()));
	        counts.foreach(new VoidFunction<Tuple2<String, Integer>>() {
	            @Override
	            public void call(Tuple2<String, Integer> stringIntegerTuple2) throws Exception {
	                System.out.println("str:" + stringIntegerTuple2._1() + "=> count:" + stringIntegerTuple2._2());
	            }
	        });
	    }
	    /**
	     * 1. 创建SparkConf
	     * 2. 创建JavaSparkContext
	     * 3. 创建JavaRDD
	     */
	    public static void firstSparkJava(){
	
	        //并行集合
	        List<Integer> list = Arrays.asList(1,23,4,4,5);
	        JavaRDD<Integer> javaRDD = sc.parallelize(list);
	        /**
	         * 打印内容
	         */
	        javaRDD.foreach(new VoidFunction<Integer>() {
	            public void call(Integer integer) throws Exception {
	                System.out.println(" " + integer);
	            }
	        });
	    }
	}
	
	```
4. 运行

> 运行时候要指定vm option `-Xms256m -Xmx1024m`,否则会抛异常

统计出单词的数量

	```
	str:name=> count:2
	str:on=> count:1
	str:come=> count:1
	str:word=> count:2
	str:hello=> count:2
	str:words=> count:1
	```

