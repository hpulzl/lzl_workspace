#windows环境下安装spark
#前言

> 花了近两周的时间学习了scala的语法，然后就迫不及待的想要玩一下spark的开发了。这里先介绍一下spark在windows环境下的安装步骤和方法。

> 因为spark大数据的计算肯定是基于分布式集群的方式才能发挥其巨大的作用，所以，在windows环境下学习大数据，只是纸上谈兵的方式。因为环境的限制，所以只能在现有的电脑上进行大数据的学习，先了解spark的API吧!先把原理搞清楚再深入实践!

> 后续的spark学习之路中，要使用scala和Java两种方式来进行本地测试和实践，通过scala的实践之路可以更加有效的了解spark的源码原理；再加上本身对java比较了解，同时，spark也是支持java开发的，所以学习java的一套API也是很有必要的!(本质上scala和java没有什么区别，只是语法表达上不一样罢了)

## jdk和scala环境的安装

* 下载JDK1.8以上

	1. 安装路径: http://www.oracle.com/technetwork/java/javase/downloads/index.html
	
	2. 环境配置
	
		```
		JAVA_HOME=G:\Java\jdk1.8.0_151
		path = G:\Java\jdk1.8.0_151\bin
		CLASS_PATH=.;
		``` 
	
	3. 验证
	
		
	> 分别使用java/javac来验证环境变量是否配置成功

* 下载scala2.10.4
	
	1. 下载地址 https://www.scala-lang.org/download/all.html
    2.  配置
    
	```
	SCALA_HOME = C:\Program Files (x86)\scala
	path = C:\Program Files (x86)\scala\bin
	```
    3.  验证
    
	> 输入scala -version 查看版本号
    
	> 输入scala 进入scala的环境
    
安装详情可以查看
http://blog.csdn.net/u011521890/article/details/78493366

**这里主要注意一下java和scala安装的路径尽量不要有空格，我的java安装路径有空格导致后续的spark无法读取到java的安装路径!**

## spark下载、安装和配置

 1. 下载

	> 下载地址: http://spark.apache.org/downloads.html，我选择的是:`Pre-built for Apache
 
 2. 安装
 	> 解压即安装
 	
 3. 环境变量配置:
	
	直接配置path就可以了

	```
	path = G:\bigData\spark-2.2.0-bin-hadoop2.6\bin
	```

## hadoop的下载、安装和配置

 1.下载

> 下载地址: https://archive.apache.org/dist/hadoop/common/hadoop-2.6.0/ (这里要和spark中选择的hadoop保持一致)，所以`hadoop-2.6.0`

 2.安装

> 解压即安装

 3.配置

分别配置`HADOOP_HOME`和`Path`

	```
	Path = G:\bigData\hadoop-2.6.4\bin
	HADOOP_HOME=G:\bigData\hadoop-2.6.4
	``` 

## 下载winutils.exe

1.下载
 > https://github.com/steveloughran/winutils（找到支持hadoop2.6.0的版本就可以了）
 
2.使用
  
 将其拷贝到~/hadoop/bin的目录下

# 运行验证Spark

1. 保证以上步骤都正确操作完成

2. 命令行输入`spark-shell`命令

3. 出现图片所示内容提示即为成功!



