# 前言
本文的spark集群部署是在windows环境下的ubuntu14.0.4的虚拟机中完成的。主要的实例包括

> 三个ubuntu虚拟机。

 **每个虚拟机中需要必要的配置**

* 静态的ip
* ssh免密码登录
* scala-2.10.4.tgz
* hadoop-2.6.4.tar.gz 
* spark-2.2.0-bin-hadoop2.6.tgz
* jdk-8u151-linux-x64.tar.gz

***技巧，可以先安装一个ubuntu虚拟机，并安装好相应的软件，然后在vmware中进行clone虚拟机的操作!***
下面描述一下以上需要安装软件的步骤:

## 配置静态ip
## 安装ssh
## jdk安装和配置
## scala的安装和配置
## hadoop的安装和配置

> /etc/hadoop 中的核心内容
> core-site.xml
> hdfs-site.xml
> slaves
> format hdfs
> 启动hdfs
> dfs => master:50070
> yarn => localhost:8088

## spark的安装和配置

## 集群的验证

踩坑:
export PATH=$PATH:/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin
 
